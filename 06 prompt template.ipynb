{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "对于文本来说，大语言模型的本质是在提示词后面继续生成新的文本，因此提示词是大语言模型的核心，它决定了语言模型的行为和输出。虽然提示词完全可以手搓，但为了方便，LangChain 提供了一些提示词模板工具，用户只需先制作模板，后续修改一些参数即可得到对应的提示词。LangChain 提供了 3 种常用的提示词模板，分别是：\n",
    "1. `PromptTemplate`：最基本的提示词模板，用户可以自定义提示词的模板，并通过传入参数得到对应的提示词。\n",
    "2. `ChatPromptTemplate`：用于聊天模型的提示词模板，可以生成聊天模型的例子，并通过传入参数得到对应的提示词。\n",
    "3. `FewShotPromptTemplate`：用于 few-shot learning 的提示词模板，可以生成 few-shot learning 的例子，并通过传入参数得到对应的提示词。\n",
    "# `PromptTemplate`\n",
    "提示词模板接受一个字典（`invoke` 方法）或命名参数（`format` 方法），键是模版参数，值是对应的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='\\nTell me a joke about cats\\n'\n",
      "\n",
      "Tell me a joke about cats\n",
      "\n",
      "Sure! Here's a joke about cats:\n",
      "Why did the cat break up with the cat?\n",
      "Because it found out she was really good at throwing cans!\n",
      "I hope that makes for a funny response! How else could I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"qwen2.5:0.5b\")\n",
    "\n",
    "template = '''\n",
    "Tell me a joke about {topic}\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "print(prompt_template.invoke({'topic':\"cats\"})) # 这两种都可以\n",
    "print(prompt_template.format(topic=\"cats\")) # 这两种都可以\n",
    "\n",
    "prompt = prompt_template.format(topic=\"cats\")\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以显式写出变量的名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Tell me a joke about cats'\n",
      "Tell me a joke about cats\n",
      "Sure! Here's a cat joke for you:\n",
      "\n",
      "Why did the cat break up with the tree?\n",
      "\n",
      "Because it wanted to have a catnap on the ground!\n",
      "\n",
      "This is a playful and lighthearted way of making a point, as if you're trying to be a bit naughty. I hope this makes your day a little less stressful!\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"], \n",
    "    template=\"Tell me a joke about {topic}\"\n",
    ")\n",
    "\n",
    "print(prompt.invoke({\"topic\":\"cats\"}))\n",
    "print(prompt.format(topic=\"cats\"))\n",
    "\n",
    "prompt = prompt.format(topic=\"cats\")\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ChatPromptTemplate`\n",
    "对话通常由不同角色的对话信息组成，例如系统信息、用户信息和助手信息，但不能一概而论，系统信息和用户信息也经常合并或缺失。构建对话提示词模板既直接接受一个结构化数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about cats', additional_kwargs={}, response_metadata={})]\n",
      "Why did the cat break up with the moon? Because it was too high up!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "print(prompt_template.invoke({\"topic\": \"cats\"}))\n",
    "\n",
    "prompt = prompt.format(topic=\"cats\")\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以接受提示词模板封装："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about cats?', additional_kwargs={}, response_metadata={})]\n",
      "Here's a cat-related joke for you:\n",
      "\n",
      "Why did the cat break up with the apple?\n",
      "\n",
      "Because it wanted to have a party!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "system_template = \"You are a helpful assistant\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"Tell me a joke about {topic}?\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "print(prompt_template.format_prompt(topic=\"cats\"))\n",
    "\n",
    "prompt = prompt.format(topic=\"cats\")\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `FewShotPromptTemplate`\n",
    "提供若干个用例可以提高模型的性能，指导大语言模型按照用户的期望生成文本。LangChain 提供了若干个用例选择器来根据用户的需求选择合适的用例。\n",
    "- `SemanticSimilarityExampleSelector`：调用大语言模型，根据语义相似度找出最相关的用例\n",
    "- `LengthBasedExampleSelector`：根据长度选择用例，长用例被选择的概率更小，短用例被选择的概率更大\n",
    "- `MaxMarginalRelevanceExampleSelector`：根据最大边际相关性找出最相关的用例\n",
    "- `NGramOverlapExampleSelector`：使用 ngram 重合度来选择最相关的例子\n",
    "\n",
    "这里以 `SemanticSimilarityExampleSelector` 为例，展示如何构建少样本学习的提示词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts.example_selector import (SemanticSimilarityExampleSelector, \n",
    "                                                LengthBasedExampleSelector, \n",
    "                                                MaxMarginalRelevanceExampleSelector, \n",
    "                                                NGramOverlapExampleSelector)\n",
    "\n",
    "samples = [\n",
    "  {\n",
    "    \"flower_type\": \"雏菊\",\n",
    "    \"occasion\": \"友情\",\n",
    "    \"ad_copy\": \"雏菊象征着纯真和真挚，是你向朋友表达友谊和温暖的贴心选择。\"\n",
    "  },\n",
    "  {\n",
    "    \"flower_type\": \"勿忘我\",\n",
    "    \"occasion\": \"离别\",\n",
    "    \"ad_copy\": \"勿忘我代表着珍重与回忆，是你在离别之际表达深情的理想花卉。\"\n",
    "  },\n",
    "  {\n",
    "    \"flower_type\": \"紫罗兰\",\n",
    "    \"occasion\": \"怀念\",\n",
    "    \"ad_copy\": \"紫罗兰象征着怀念与永恒，是你缅怀过去美好时光的优雅选择。\"\n",
    "  },\n",
    "  {\n",
    "    \"flower_type\": \"郁金香\",\n",
    "    \"occasion\": \"祝福\",\n",
    "    \"ad_copy\": \"郁金香象征着美好与幸福，是你送上诚挚祝福的理想选择。\"\n",
    "  },\n",
    "  {\n",
    "    \"flower_type\": \"勿忘我\",\n",
    "    \"occasion\": \"回忆\",\n",
    "    \"ad_copy\": \"勿忘我寓意着真挚的情感，是你寄托思念和回忆的最佳选择。\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先创建一个提示词模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲜花类型: 雏菊\n",
      "场合: 友情\n",
      "文案: 雏菊象征着纯真和真挚，是你向朋友表达友谊和温暖的贴心选择。\n"
     ]
    }
   ],
   "source": [
    "prompt_sample = PromptTemplate(input_variables=[\"flower_type\", \"occasion\", \"ad_copy\"], \n",
    "                               template=\"鲜花类型: {flower_type}\\n场合: {occasion}\\n文案: {ad_copy}\")\n",
    "print(prompt_sample.format(**samples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FewShotPromptTemplate` 包含若干个参数，主要参数有：\n",
    "- `example_prompt`：用来格式化每条用例的模板\n",
    "- `example_selector`：用例选择器\n",
    "- `examples`：具体用例\n",
    "- `prefix`：前缀，用来提示模型如何使用数据\n",
    "- `suffix`：后缀，用来提示模型输出的格式\n",
    "- `input_variables`：输入变量，用来指定模板中需要填充的变量\n",
    "- `partial_variables`：部分变量，用来指定模板中需要填充的变量，但值不是在模板中指定的，而是通过其他方式提供的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['ad_copy', 'flower_type', 'occasion'] input_types={} partial_variables={} template='鲜花类型：{flower_type}\\n场合：{occasion}\\n文案：{ad_copy}'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_sample = PromptTemplate(template='鲜花类型：{flower_type}\\n场合：{occasion}\\n文案：{ad_copy}', \n",
    "                               input_variables=['flower_type', 'occasion', 'ad_copy'])\n",
    "print(prompt_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是鲜花类型和场合的对应关系，请根据occasion给出对应的鲜花类型：\n",
      "\n",
      "鲜花类型：雏菊\n",
      "场合：友情\n",
      "文案：雏菊象征着纯真和真挚，是你向朋友表达友谊和温暖的贴心选择。\n",
      "\n",
      "鲜花类型：勿忘我\n",
      "场合：离别\n",
      "文案：勿忘我代表着珍重与回忆，是你在离别之际表达深情的理想花卉。\n",
      "\n",
      "鲜花类型：紫罗兰\n",
      "场合：怀念\n",
      "文案：紫罗兰象征着怀念与永恒，是你缅怀过去美好时光的优雅选择。\n",
      "\n",
      "鲜花类型：郁金香\n",
      "场合：祝福\n",
      "文案：郁金香象征着美好与幸福，是你送上诚挚祝福的理想选择。\n",
      "\n",
      "鲜花类型：勿忘我\n",
      "场合：回忆\n",
      "文案：勿忘我寓意着真挚的情感，是你寄托思念和回忆的最佳选择。\n",
      "\n",
      "鲜花类型：玫瑰\n",
      "场合：生日\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=samples,\n",
    "    example_prompt=prompt_sample,\n",
    "    prefix='以下是鲜花类型和场合的对应关系，请根据occasion给出对应的鲜花类型：',\n",
    "    suffix='鲜花类型：{flower_type}\\n场合：{occasion}',\n",
    "    input_variables=['flower_type', 'occasion']\n",
    ")\n",
    "print(prompt.format(flower_type='玫瑰', occasion='生日'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FewShotPromptTemplate` 需要借助词嵌入模型、向量数据库和大语言模型完成对语义相近的 few-shot 示例的检索，从而完成 few-shot 提示词模板的构建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲜花类型：郁金香\n",
      "场合：祝福\n",
      "文案：郁金香象征着美好与幸福，是你送上诚挚祝福的理想选择。\n",
      "\n",
      "鲜花类型：红玫瑰\n",
      "场合：爱情\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name='BAAI/bge-small-zh-v1.5')\n",
    "llm = OllamaLLM(model=\"qwen2.5:0.5b\")\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    samples, embedding, FAISS, k=1\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=prompt_sample,\n",
    "    suffix='鲜花类型：{flower_type}\\n场合：{occasion}',\n",
    "    input_variables=['flower_type', 'occasion']\n",
    ")\n",
    "print(prompt.format(flower_type='红玫瑰', occasion='爱情'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样就生成了一条包含于查询相关的用例的提示词。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
